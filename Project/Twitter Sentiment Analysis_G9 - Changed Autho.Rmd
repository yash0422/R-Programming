---
title: "Twitter Sentiment Analysis"
author: "Vishal Desai"
date: "5/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r INSTALL REQUIRED LIBRARIES}

library(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(ggplot2)
library(httr)
library(wordcloud)
library(RCurl)
library(syuzhet)
library(SentimentAnalysis)
library(sentimentr)
library(tm)
library(dplyr)
library(SnowballC)

```

```{r ACCESS TWITTER API}

oauth_endpoint(authorize = "https://api.twitter.com/oauth",
               access = "https://api.twitter.com/access_token")

# Connect to API

download.file(url = "http://curl.haxx.se/ca/cacert.pem", destfile = "cacert.pem")
reqURL = "http://api.twitter.com/oauth/request_token"
accessURL = "http://api.twitter.com/oauth/access_token"
authURL = "http://api.twitter.com/oauth/authorize"

```

```{r AUTHORIZE TWITTER API ACCESS}

consumerKey = "lSvXIeZjmGqnSPUdI"
consumerSecret = "Vo2OMa6MR7rNAQMmKvSUTcE0FrJWR84RRmTu"
accessToken = "3522837792-TZyALnYqZqBfCOcPokFsBqtMr3"
accessSecret = "maEsQgrtNpc12S6AyjEf5R2pxqnL"

```

```{r AUTHORIZE TWITTER ACCESS}

Cred = OAuthFactory$new(consumerKey = consumerKey,
                        consumerSecret = consumerSecret,
                        requestURL = reqURL,
                        accessURL = accessURL,
                        authURL = authURL)

Cred$handshake(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl'))
# There is URL in console, you need to go to it get code and enter it on console.

save(Cred, file = 'twitter authentication.Rdata')

load('twitter authentication.Rdata')

setup_twitter_oauth(consumer_key = consumerKey, consumer_secret = consumerSecret, access_token = accessToken, access_secret = accessSecret)
```

```{r TWEETS EXTRACTION}

# HARVEST TERMS/TWEETS FOR EXTRACTION 
air_arabia_tweets = searchTwitter("Air Arabia", n = 1000, since = "2019-01-01", lang ="en")

# Check LENGTH of Tweets
length.air_arabia_tweets = length(air_arabia_tweets)
length.air_arabia_tweets

# Export the Extracted Tweets to DataFrame
air_arabia_tweets.df = ldply(air_arabia_tweets, function(t) t$toDataFrame())
write.csv(air_arabia_tweets.df, "g9_tweets.csv")

```

```{r EXTRACT TEXT FROM TWEETS}

#Extract text from the tweets

g9_tweets_text = sapply(air_arabia_tweets, function(x) x$getText())
class(g9_tweets_text)
g9_tweets_text[[1]]

```

```{r DATA CLEANING}

# Remove people name, RT text, etc.
g9_tweets_text_1 = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", g9_tweets_text)
#write.csv(g9_tweets_text_1, "g9_tweets_text_1.csv")

# Remove html links
g9_tweets_text_2 = gsub("http[^[:blank:]]+", " ", g9_tweets_text_1)
#write.csv(g9_tweets_text_2, "g9_tweets_text_2.csv")

# Remove people names
g9_tweets_text_3 = gsub("@\\w+", " ", g9_tweets_text_2)
#write.csv(g9_tweets_text_3, "g9_tweets_text_3.csv")

# Remove Punctuations
g9_tweets_text_4 = gsub("[[:punct:]]", " ", g9_tweets_text_3)
#write.csv(g9_tweets_text_4, "g9_tweets_text_4.csv")

# Remove Numbers
g9_tweets_text_5 = gsub("[^[:alnum:]]", " ", g9_tweets_text_4)
#write.csv(g9_tweets_text_5, "g9_tweets_text_5.csv")

# Exporting to Excel
write.csv(g9_tweets_text_5, "g9_tweets_01.csv")

```

```{r CREATE WORDCORPUS CLEANING}

library("tm")
library("dplyr")
library("SnowballC")

g9_tweets_text_6 = Corpus(VectorSource(g9_tweets_text_5))
g9_tweets_text_6 = tm_map(g9_tweets_text_6, removePunctuation)
g9_tweets_text_6 = tm_map(g9_tweets_text_6, content_transformer(tolower))
g9_tweets_text_6 = tm_map(g9_tweets_text_6, removeWords, stopwords("english"))
g9_tweets_text_6 = tm_map(g9_tweets_text_6, stripWhitespace)
#write.csv(g9_tweets_text_6, "g9_tweets_text_6")

```

```{r BUILDING WORD CLOUD}

pal = brewer.pal(8, "Dark2")
wordcloud(g9_tweets_text_6, min.freq  = 5, max.words = Inf,
          width = 1000, height = 1000, random.order = FALSE, colors = pal)

```

```{r SENTIMENT ANALYSIS}

# How the function work
get_nrc_sentiment("I bought an iPhone a few days ago. It is such a nice phone, although a little large. The touch screen is cool. The voice quality is clear too. I simply love it!")

```

```{r RUNNING SENTIMENT ANALYSIS ON OUR DATA}

mysentiment = get_nrc_sentiment(g9_tweets_text_5)
SentimentScores = data.frame(colSums(mysentiment[,]))
names(SentimentScores) = "Score"
SentimentScores = cbind("sentiment" = rownames(SentimentScores), SentimentScores)
rownames(SentimentScores) = NULL
ggplot(data = SentimentScores, aes(x = sentiment, y = Score)) +
  geom_bar(aes(fill = sentiment), stat = "identity")
  theme(legend.position = "none")
  xlab("Sentiment"), ylab("Score"), ggtitle("Total Sentiment Score Based on Tweets")
  
```
